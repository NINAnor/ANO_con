# Read data from the database

```{r setup2}
#| include: false
#| message: false
#| error: false
library(tidyverse)
library(dbplyr)
library(DBI)
library(RPostgres)
library(dm)
```

## Overview
Now that we have added data to the database, we can also read it back.

```{r}
#| eval: true
#| include: false
con <- DBI::dbConnect(drv = RPostgres::Postgres(), host = "t2lippgsql03", dbname = "ano_moduler")
```

```{r}
#| eval: true
coast_sample <- dplyr::tbl(con, dbplyr::in_schema("sampling_frames", "samplingframe_havstrand_2024"))
coast_sample
```

Same for the wetlands samples:
```{r}
#| eval: true
vaatmark_2025 <- dplyr::tbl(con, dbplyr::in_schema("samples", "vaatmark_2025"))
```


## Collect and join data
This data only exists remotely still.
We need to use collect to bring it down to our local machine. 
At the same time we can use dplyr pipelines to filter the data.

```{r}
#| eval: true
coast_sample |>
  dplyr::mutate(id = row_number()) |>
  dplyr::slice_min(n = 8, order_by = id) |>
  dplyr::collect()
```

We can also get the geometries, which are stored in the foreign table.
To do this we can use the dm package.

We first create a dm object from the connection object.
Then we can view data easily.
```{r}
#| eval: true
dm <- dm::dm_from_con(con,
  table_names = c(
    "ssb_500",
    "vaatmark_2025"
  ),
  learn_keys = T
)
dm
```

DM learns the relationships between tables by reading the constraints. 
First I can check that the amount of constraints is good.

```{r}
#| eval: true
dm::dm_get_all_fks(dm)
```

```{r}
#| eval: true
dm |>
  dm::dm_set_colors(
    darkgreen = vaatmark_2025, 
    darkblue = ssb_500) |>
  dm::dm_draw() 
```

Then we can read the data back, including the geometries from the parent table.
The geometries are stores (or at least returned) as hex-encoded WKB/EWKB, and we need to convert then to sfc first, before we can turn them into sf.
```{r}
#| eval: false
dm2 <- dm |>
  dm::dm_flatten_to_tbl(vaatmark_2025,
                    .recursive = TRUE) |>
  mutate(geom_wkb = dbplyr::sql("ST_AsBinary(geom)")) |>
  select(-geom) |>
  collect() |>
  mutate(geom = sf::st_as_sfc(geom_wkb, crs = 25833)) |>
  sf::st_as_sf(sf_column_name = "geom")

```

Then I export this as a geopackage
```{r}
path <- "/data/Egenutvikling/41001581_egenutvikling_anders_kolstad/ANO"
st_write(dm2, paste0(path, "/vaatmark_2025_1000_10.gpkg"), append = FALSE)
```

```{r}
library(tmap)
tmap_mode("view")

dm2 |>
  select(ssbid, geom, `150`) |>
  drop_na(`150`) |>
tm_shape() +
  tm_borders(col = "darkgreen", lwd = 10)
```
```{r}
dm2 |>
  select(ssbid, geom, `50`) |>
  drop_na(`50`) |>
  slice_head(n = 1000) |>
tm_shape() +
  tm_borders(col = "blue", lwd = 10)
```

![](img/vaatmark1_150.jpg)


![](img/vaatmark1_50.jpg)

### Collect bioclimatic dataset

```{r}
#| eval: true
bc <- dplyr::tbl(con, dbplyr::in_schema("helper_variables", "bioclimatic_regions"))
```


```{r}
#| eval: false
bc <- bc |>
  mutate(geom_wkb = dbplyr::sql("ST_AsBinary(geom)")) |>
  select(-geom) |>
  collect() |>
  mutate(geom = sf::st_as_sfc(geom_wkb, crs = 25833)) |>
  sf::st_as_sf(sf_column_name = "geom")


reg <- unique(bc2$BCregion)
bc2 <- bc |>
  mutate(BCregion = case_when(
    BCregion == reg[1] ~ 2,
    BCregion == reg[2] ~ 1,
    BCregion == reg[3] ~ 3,
    BCregion == reg[4] ~ 5,
    BCregion == reg[5] ~ 7,
    BCregion == reg[6] ~ 6,
    BCregion == reg[7] ~ 4,
    BCregion == reg[8] ~ 8,
    BCregion == reg[9] ~ 4,
    BCregion == reg[10] ~ 9,
    BCregion == reg[11] ~ 1,
    BCregion == reg[12] ~ 7,
  ))

bc3 <- bc2 |>
  group_by(BCregion) |>
  summarise()
tmap_mode("plot")

pal <- tmaptools::get_brewer_pal("Paired", n = 9)

map<- bc3 |>
  tm_shape()+
  tm_polygons(col="BCregion", style="cat", palette = pal, lwd=0)
map
#tmap_save(map, "img/bcMap.png")
```


![](img/bcMap.png)



