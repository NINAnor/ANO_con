[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Working with the ANO-moduler database",
    "section": "",
    "text": "Introduction\nThis web site show you how to connect to the internal NINA postgreSQL database containing the spatial data for the ANO-modules. The database is found on the t2lippgsql03 server , and is called ano_moduler. This with admin rights are\nThe database contains the raw data needed to make balanced spatial samples of monitoring localities for ANO-modules.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Working with the ANO-moduler database",
    "section": "",
    "text": "Anders Kolstad (anders.kolstad@nina.no)\nJens Åström (jens.astrom@nina.no)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "001_connecting.html",
    "href": "001_connecting.html",
    "title": "\n1  Connecting to the database\n",
    "section": "",
    "text": "Fisrt you need to save your personal windows password to your local machine.. Don’t write it in your code. If you’re on linux, you can store it in your personal root folder like this (just change the ‘secretPassword’ to you own):\n\nsystem(\"echo '*:*:*:*:secretPassword' &gt; ~/.pgpass\")\nsystem(\"chmod 0600 ~/.pgpass\")\n\nThen you can connect:\n\ncon &lt;- DBI::dbConnect(drv = RPostgres::Postgres(), host = \"t2lippgsql03\", dbname = \"ano_moduler\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Connecting to the database</span>"
    ]
  },
  {
    "objectID": "010_SSB500.html",
    "href": "010_SSB500.html",
    "title": "2  SSB500",
    "section": "",
    "text": "2.1 Setup schema\nSetting up a new schema called ssb_grids. Here we can store SSB500, but also SSB10km which may become relevant.\nnew_schemas &lt;- \"CREATE SCHEMA ssb_grids\"\ndbSendQuery(con, new_schemas)\nWrite queries to grant read only access to all.\npriv &lt;- \"ALTER DEFAULT PRIVILEGES IN SCHEMA ssb_grids GRANT SELECT ON TABLES TO ag_pgsql_ano_moduler_ro\"\n\npriv2 &lt;- \"ALTER DEFAULT PRIVILEGES IN SCHEMA ssb_grids GRANT SELECT ON TABLES TO ag_pgsql_ano_moduler_rw\"\n\npriv3 &lt;- \"ALTER DEFAULT PRIVILEGES IN SCHEMA ssb_grids GRANT SELECT ON TABLES TO ag_pgsql_ano_moduler_admin\"\n\npriv4 &lt;- \"GRANT USAGE ON SCHEMA ssb_grids  TO ag_pgsql_ano_moduler_admin\"\npriv5 &lt;- \"GRANT USAGE ON SCHEMA ssb_grids  TO ag_pgsql_ano_moduler_rw\"\npriv6 &lt;- \"GRANT USAGE ON SCHEMA ssb_grids  TO ag_pgsql_ano_moduler_ro\"\n\ndbSendStatement(con, priv)\ndbSendStatement(con, priv2)\ndbSendStatement(con, priv3)\ndbSendStatement(con, priv4)\ndbSendStatement(con, priv5)\ndbSendStatement(con, priv6)",
    "crumbs": [
      "Write geographic data to the database",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SSB500</span>"
    ]
  },
  {
    "objectID": "010_SSB500.html#read-data-into-r",
    "href": "010_SSB500.html#read-data-into-r",
    "title": "2  SSB500",
    "section": "\n2.2 Read data into R",
    "text": "2.2 Read data into R\nWe use RStudio as the interface when adding new data to the database. We start by bringing the data into our environment.\nFirst we can get the entire SSB500 dataset.\n\nSSBpath &lt;- \"/data/P-Prosjekter2/412421_okologisk_tilstand_2024/Data/SSB0500M_L/ruter500m_Norge.shp\"\nSSB500 &lt;- read_sf(SSBpath) |&gt;\n  st_transform(25833)\n\nStrip down the number of columns\n\nSSB500 &lt;- SSB500 |&gt;\n  select(ssbid = SSBid) # postgre doesnt like capital letters\n\n# the geometry column needs to be named 'geom'\nst_geometry(SSB500) &lt;- \"geom\"\n\nThis data consists of perfect 500x500 grid cells arranged on rounded coordinates in the UTM sone 33 CRS.",
    "crumbs": [
      "Write geographic data to the database",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SSB500</span>"
    ]
  },
  {
    "objectID": "010_SSB500.html#define-table-properties",
    "href": "010_SSB500.html#define-table-properties",
    "title": "2  SSB500",
    "section": "\n2.3 Define table properties",
    "text": "2.3 Define table properties\nFirst we define the table properties\n\nq1 &lt;- \"create table ssb_grids.ssb_500 (\nssbid character varying(50) primary key,\ngeom geometry(polygon,25833)\n);\"\n\n# indices makes the database work faster. It should be added to all tables that are looked up frequently\nq2 &lt;- \"create index on ssb_grids.ssb_500 using btree(ssbid);\"\nq3 &lt;- \"create index on ssb_grids.ssb_500 using gist(geom);\"\n\n\n# sending the queries:\ndbSendStatement(con, q1)\ndbSendStatement(con, q2)\ndbSendStatement(con, q3)\n\nWe defined geom to be polygon. Now let’s just check that that is true, and there are no multi-polygons for example.\n\nst_geometry_type(SSB500, by_geometry = F)\n\nYes, they are all polygons.",
    "crumbs": [
      "Write geographic data to the database",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SSB500</span>"
    ]
  },
  {
    "objectID": "010_SSB500.html#write-to-db",
    "href": "010_SSB500.html#write-to-db",
    "title": "2  SSB500",
    "section": "\n2.4 Write to db",
    "text": "2.4 Write to db\nThen we write data to the ssb_500 table.\n\nwrite_sf(SSB500, dsn = con,\n         layer = Id(schema = \"ssb_grids\", table = \"ssb_500\"), \n         append = T)",
    "crumbs": [
      "Write geographic data to the database",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>SSB500</span>"
    ]
  },
  {
    "objectID": "011_bioclimatic_regions.html",
    "href": "011_bioclimatic_regions.html",
    "title": "\n3  Bioclimatic regions\n",
    "section": "",
    "text": "3.1 Setup schema\nSetting up a new schema called helper_variables. Here we can store helper variables that we use to either stratify or balance our spatial sample.\nnew_schemas &lt;- \"CREATE SCHEMA helper_variables\"\ndbSendQuery(con, new_schemas)\nWrite queries to grant read only access to all.\npriv &lt;- \"ALTER DEFAULT PRIVILEGES IN SCHEMA helper_variables GRANT SELECT ON TABLES TO ag_pgsql_ano_moduler_ro\"\n\npriv2 &lt;- \"ALTER DEFAULT PRIVILEGES IN SCHEMA helper_variables GRANT SELECT ON TABLES TO ag_pgsql_ano_moduler_rw\"\n\npriv3 &lt;- \"ALTER DEFAULT PRIVILEGES IN SCHEMA helper_variables GRANT SELECT ON TABLES TO ag_pgsql_ano_moduler_admin\"\n\npriv4 &lt;- \"GRANT USAGE ON SCHEMA helper_variables  TO ag_pgsql_ano_moduler_admin\"\npriv5 &lt;- \"GRANT USAGE ON SCHEMA helper_variables  TO ag_pgsql_ano_moduler_rw\"\npriv6 &lt;- \"GRANT USAGE ON SCHEMA helper_variables  TO ag_pgsql_ano_moduler_ro\"\n\ndbSendStatement(con, priv)\ndbSendStatement(con, priv2)\ndbSendStatement(con, priv3)\ndbSendStatement(con, priv4)\ndbSendStatement(con, priv5)\ndbSendStatement(con, priv6)",
    "crumbs": [
      "Write geographic data to the database",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bioclimatic regions</span>"
    ]
  },
  {
    "objectID": "011_bioclimatic_regions.html#define-table-properties",
    "href": "011_bioclimatic_regions.html#define-table-properties",
    "title": "\n3  Bioclimatic regions\n",
    "section": "\n3.2 Define table properties",
    "text": "3.2 Define table properties\nFirst we define the table properties\n\nq1 &lt;- \"create table helper_variables.bioclimatic_regions (\nssb1000id character varying(50) primary key,\ngeom geometry(polygon,25833)\n);\"\n\n# indices makes the database work faster. It should be added to all tables that are looked up frequently\nq2 &lt;- \"create index on helper_variables.bioclimatic_regions using btree(ssb1000id);\"\nq3 &lt;- \"create index on helper_variables.bioclimatic_regions using gist(geom);\"\n\n\n# sending the queries:\ndbSendStatement(con, q1)\ndbSendStatement(con, q2)\ndbSendStatement(con, q3)\n\nI set the geom column to be *polygon’, but it’s actually a multipolygon. This could cause errors down the line.\n\nst_geometry_type(BCreg, by_geometry = F)\n\nI therefore ran this code in DBBeaver\n\nALTER TABLE HELPER_VARIABLES.BIOCLIMATIC_REGIONS \nALTER COLUMN geom TYPE geometry(MULTIPOLYGON, 25833)",
    "crumbs": [
      "Write geographic data to the database",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bioclimatic regions</span>"
    ]
  },
  {
    "objectID": "011_bioclimatic_regions.html#write-to-db",
    "href": "011_bioclimatic_regions.html#write-to-db",
    "title": "\n3  Bioclimatic regions\n",
    "section": "\n3.3 Write to db",
    "text": "3.3 Write to db\nThen I will write the file to the database.\n\n# turn back into sf object\nBCreg &lt;- BCreg |&gt;\n  st_as_sf()\n\n# check CRS\nst_crs(BCreg) #32633 (we want 25833 i.e. ETRS89 / UTM zone 33N)\n\n# transform\nBCreg &lt;- BCreg |&gt;\n  st_transform(25833)\n\nBCreg &lt;- BCreg |&gt;\n  select(\n    ssb1000id = SSBID,\n    BCregion,\n    Shape\n  )\n# special code to rename the geometry\nst_geometry(BCreg) &lt;- \"geom\"\n\nwrite_sf(BCreg, dsn = con,\n         layer = Id(schema = \"helper_variables\", table = \"bioclimatic_regions\"), \n         append = T)\n\nI also forgot to add a column, so I add it now:\n\nq4 &lt;- \"ALTER TABLE helper_variables.bioclimatic_regions ADD BCregion character varying(50)\"\ndbSendStatement(con, q4)\n\nAnd then update the table with data as well\n\nwrite_sf(BCreg, dsn = con,\n         layer = Id(schema = \"helper_variables\", table = \"bioclimatic_regions\"), \n         append = F)\n\nI also keep a version on the R: server\n\npath_store &lt;- \"/data/P-Prosjekter2/412421_okologisk_tilstand_2024/Data/bioclimaticRegions.gpkg\"\nwrite_sf(BCreg, dsn = path_store,driver = \"GPKG\")\n\n\nlist.files(\"/home/\")\n\n\n\n\n\nBakkestuen, V., Erikstad, L., and Halvorsen, R. 2008. Step-less models for regional environmental variation in Norway. Journal of Biogeography 35(10): 1906–1922. doi:10.1111/j.1365-2699.2008.01941.x.",
    "crumbs": [
      "Write geographic data to the database",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bioclimatic regions</span>"
    ]
  },
  {
    "objectID": "020_samplingFrames.html",
    "href": "020_samplingFrames.html",
    "title": "\n4  Sampling frames\n",
    "section": "",
    "text": "4.1 Setup schema\nThis part sets up the schema, and is only done ones.\nschema_ur &lt;- \"CREATE SCHEMA sampling_frames\"\ndbSendQuery(con, schema_ur)\nWrite queries to grant read only access to all.\npriv &lt;- \"ALTER DEFAULT PRIVILEGES IN SCHEMA sampling_frames GRANT SELECT ON TABLES TO ag_pgsql_ano_moduler_ro\"\npriv2 &lt;- \"ALTER DEFAULT PRIVILEGES IN SCHEMA sampling_frames GRANT SELECT ON TABLES TO ag_pgsql_ano_moduler_rw\"\npriv3 &lt;- \"ALTER DEFAULT PRIVILEGES IN SCHEMA sampling_frames GRANT SELECT ON TABLES TO ag_pgsql_ano_moduler_admin\"\npriv4 &lt;- \"GRANT USAGE ON SCHEMA sampling_frames  TO ag_pgsql_ano_moduler_admin\"\npriv5 &lt;- \"GRANT USAGE ON SCHEMA sampling_frames  TO ag_pgsql_ano_moduler_rw\"\npriv6 &lt;- \"GRANT USAGE ON SCHEMA sampling_frames  TO ag_pgsql_ano_moduler_ro\"\n\ndbSendStatement(con, priv)\ndbSendStatement(con, priv2)\ndbSendStatement(con, priv3)\ndbSendStatement(con, priv4)\ndbSendStatement(con, priv5)\ndbSendStatement(con, priv6)",
    "crumbs": [
      "Write tabular data to the database",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling frames</span>"
    ]
  },
  {
    "objectID": "020_samplingFrames.html#ano-våtmark",
    "href": "020_samplingFrames.html#ano-våtmark",
    "title": "\n4  Sampling frames\n",
    "section": "\n4.2 ANO våtmark",
    "text": "4.2 ANO våtmark\nHere we upload the dataframe with SSB-id’s that make up the sampling frame for ANO våtmark (wetlands). The dataframe also contain auxillary variables used for balansing and stratifying the sampling. All the datasets and code (python) to create this dataframe if or will be uploaded to the database as well.\nRead data into R:\n\nlibrary(readr)\ndat &lt;- read_delim(\"/data/P-Prosjekter2/412421_okologisk_tilstand_2024/Jan/ruter500m_Norge.csv\", \n    delim = \";\", escape_double = FALSE,  trim_ws = TRUE)\n\n# removing some columns\ndat &lt;- dat |&gt;\n  select(-Join_Count,\n         -TARGET_FID,\n         -Shape_Leng,\n         -Shape_Length,\n         -Shape_Area)\n\n# There are some columns that should be numeric, but are read initial as characters with leading apostrophes and the wrong decimal sign.\ntoConvert &lt;- c(\n  \"rFerskvann\",\n  \"rHav\",\n  \"rSnoIsbre\",\n  \"rBebygdSamf\",\n  \"minSlope\",\n  \"meanSlope\",\n  \"maxSlope\"\n)\n\ndat &lt;- dat |&gt;\n  mutate(across(toConvert, ~ gsub(\"^'\", \"\", .))) |&gt;\n  mutate(across(toConvert, ~ gsub(\",\", \".\", .))) |&gt;\n  mutate(across(toConvert, as.numeric)) |&gt;\n  mutate(across(toConvert, \\(x) round(x, digits = 5))) |&gt;\n  rename(ssbid = SSBid)\n\nWe start with 1 880 382 sampling units, but we want to exclude sampling units with 100% water (ocean or freshwater). There are 516201 units of marine waters and 13263 with freshwater. We could perhaps also exclude units with 100% build up area, but I’m at this moment not sure we can be fully sure there is no wetland in those units. Units with snow and ice are kept, becaus ethey can become wetalnds in a few decades.\n\ndat_full &lt;- dat\n\nnrow(dat_full[dat_full$rHav == 100,])\nnrow(dat_full[dat_full$rFerskvann == 100,])\n  \ndat &lt;- dat |&gt;\n  dplyr::filter(rHav &lt; 100 & rFerskvann &lt;100)\n\nnrow(dat_full)-nrow(dat) # 529464 Correct\nnrow(dat) #1350918\nnrow(dat)/4 # 337 729.5\n\n\nanyDuplicated(dat$ssbid) # no duplicates\n\nNow we are down to 1 644 092 units. If we divide by 4 to get km2, we get a little higher than the true value for the Norwegian mainland, which is as expected since we include some coastal waters.\nWe also need a primary key, and therefore I add a unique identifier.\n\nids &lt;- uuid::UUIDgenerate(n = nrow(dat))\nanyDuplicated(ids)\ndat &lt;- dat |&gt;\n  mutate(\n    vaatmark_id = ids\n  )\n\n\ndat &lt;- dat |&gt;\n  select(\n    ssbid,\n    vaatmark_id,\n    ost,\n    nord,\n    centroid_x = CENTROID_X,\n    centroid_y = CENTROID_Y,\n    komm2016 = Komm2016,\n    fylk2016 = Fylk2016,\n    r_ferskvann = rFerskvann,\n    r_hav = rHav,\n    r_sno_isbre = rSnoIsbre,\n    r_bebygd_samf = rBebygdSamf,\n    mean_slope = meanSlope,\n    ssbid_1000 = SSBid_1000,\n    sone_kode = Sone_kode,\n    seksjon_kode = Seksjon_kode,\n    abi = ABI)\n\n\n4.2.1 Define table properties\nWe will name the table samplingframe_vaatmark_2025.\n\nq1 &lt;- \"create table sampling_frames.samplingframe_vaatmark_2025 (\nvaatmark_id character varying(50) primary key,\nssbid character varying(50),\nost integer,\nnord integer,\ncentroid_x numeric(24,0),\ncentroid_y numeric(24,0),\nkomm2016 character varying(5),\nfylk2016 character varying(5),\nr_ferskvann numeric(10,5),\nr_hav numeric(10,5),\nr_sno_isbre numeric(10,5),\nr_bebygd_samf numeric(10,5),\nmean_slope numeric(10,5),\nssbid_1000 numeric(15,0),\nsone_kode character varying(7),\nseksjon_kode character varying(7),\nabi integer,\nCONSTRAINT fk_ssb_500\n      FOREIGN KEY (ssbid)\n        REFERENCES ssb_grids.ssb_500 (ssbid)\n);\"\n\n# indices makes the database work faster. It should be added to all tables that are looked up frequently\nq2 &lt;- \"create index on sampling_frames.samplingframe_vaatmark_2025 using btree(ssbid);\"\nq3 &lt;- \"create index on sampling_frames.samplingframe_vaatmark_2025 using btree(vaatmark_id);\"\n\n\n# sending the queries:\ndbSendStatement(con, q1)\ndbSendStatement(con, q2)\ndbSendStatement(con, q3)\n\n\n4.2.2 Write to db\nThen we write data to the samplingframe_havstrand_2024 table.\n\nwrite_sf(dat, dsn = con,\n         layer = Id(schema = \"sampling_frames\", table = \"samplingframe_vaatmark_2025\"), \n         append = T)",
    "crumbs": [
      "Write tabular data to the database",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling frames</span>"
    ]
  },
  {
    "objectID": "020_samplingFrames.html#ano-havstrand",
    "href": "020_samplingFrames.html#ano-havstrand",
    "title": "\n4  Sampling frames\n",
    "section": "\n4.3 ANO Havstrand",
    "text": "4.3 ANO Havstrand\nFor ANO Havstrand (ANO Coast), SSB500 has been masked to only include grid cells that overlap with the Norwegian coastline. The script for doing that is written in python ad can be found here: /data/P-Prosjekter2/412421_okologisk_tilstand_2024/Jan/\nRead data into R:\n\ncoast_path &lt;- \"/data/P-Prosjekter2/412421_okologisk_tilstand_2024/Jan/CoastalSampling3.gdb\"\n\nsf::st_layers(coast_path)\n\nDriver: OpenFileGDB \nAvailable layers:\n                layer_name     geometry_type features fields\n1            fcNorgeKyst_l Multi Line String   101331      2\n2 fcKystline_500mSegmenter Multi Line String   240861      1\n3              Samples62_5       Multi Point   769342      2\n4              Samples83_3       Multi Point   555958      2\n5               Samples125       Multi Point   350676      2\n6            SSB500_Coast4     Multi Polygon   121920      6\n7        Hexagon62_5_Coast     Multi Polygon  2729978      3\n8        Hexagon83_3_Coast     Multi Polygon  1622139      3\n9         Hexagon125_Coast     Multi Polygon   796190      3\n               crs_name\n1 ETRS89 / UTM zone 33N\n2 ETRS89 / UTM zone 33N\n3 ETRS89 / UTM zone 33N\n4 ETRS89 / UTM zone 33N\n5 ETRS89 / UTM zone 33N\n6 ETRS89 / UTM zone 33N\n7 WGS 84 / UTM zone 33N\n8 WGS 84 / UTM zone 33N\n9 WGS 84 / UTM zone 33N\n\n\nSSB500_Coast4 contains the SSB500 grid cells that overlap with the coastline.\n\ncoastSSB &lt;- read_sf(coast_path, layer = \"SSB500_Coast4\")\n\nThe SSBid will be the foreign key, linking to ssb_500. We also need a primary key, and therefore I add a unique identifier.\n\nids &lt;- UUIDgenerate(n = nrow(coastSSB))\nanyDuplicated(ids)\ncoastSSB &lt;- coastSSB |&gt;\n  select(ssbid = SSBid)|&gt;\n  mutate(havstrand_id = ids)\n\nWe don’t need the geometry\n\ncoastSSB &lt;- as_tibble(coastSSB) |&gt;\n  select(ssbid, havstrand_id)\n\n\n4.3.1 Define table properties\nWe will name the table samplingframe_havstrand_2024.\n\nq1 &lt;- \"create table sampling_frames.samplingframe_havstrand_2024 (\nhavstrand_id character varying(50) primary key,\nssbid character varying(50),\nCONSTRAINT fk_ssb_500\n      FOREIGN KEY (ssbid)\n        REFERENCES ssb_grids.ssb_500 (ssbid)\n);\"\n\n# indices makes the database work faster. It should be added to all tables that are looked up frequently\nq2 &lt;- \"create index on sampling_frames.samplingframe_havstrand_2024 using btree(ssbid);\"\nq3 &lt;- \"create index on sampling_frames.samplingframe_havstrand_2024 using btree(havstrand_id);\"\n\n\n# sending the queries:\ndbSendStatement(con, q1)\ndbSendStatement(con, q2)\ndbSendStatement(con, q3)\n\n\n4.3.2 Write to db\nThen we write data to the samplingframe_havstrand_2024 table.\n\nwrite_sf(coastSSB, dsn = con,\n         layer = Id(schema = \"sampling_frames\", table = \"samplingframe_havstrand_2024\"), \n         append = T)",
    "crumbs": [
      "Write tabular data to the database",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling frames</span>"
    ]
  },
  {
    "objectID": "021_readFromDb.html",
    "href": "021_readFromDb.html",
    "title": "\n5  Read data from the database\n",
    "section": "",
    "text": "Now that we have added data to the database, we can also read it back.\n\ncoast_sample &lt;- dplyr::tbl(con, dbplyr::in_schema(\"sampling_frames\", \"samplingframe_havstrand_2024\"))\ncoast_sample\n\n# Source:   SQL [?? x 2]\n# Database: postgres  [anders.kolstad@t2lippgsql03:5432/ano_moduler]\n   havstrand_id                         ssbid         \n   &lt;chr&gt;                                &lt;chr&gt;         \n 1 4de8478a-d2c8-4730-83dd-12ac25d4fa07 22495006594500\n 2 bc9a80d7-c434-47e9-a89a-7f7a3f59f625 22495006595000\n 3 ce7166b6-cb49-499a-a99f-9da0e274abd8 22495006595500\n 4 e56036c5-7fe4-461a-a022-44367119acac 22495006596000\n 5 1f592dac-2fb7-49e5-9aa9-fc0cf9e9184f 22490006596500\n 6 20394fe8-305c-4c39-add9-f013295ca932 22495006596500\n 7 3d3ffe94-0400-4c1c-9a0f-62f4d6c29c4d 22490006597000\n 8 4d199401-dd20-48ef-b6c6-8de00b9eb9a4 22495006597000\n 9 a34df6f4-8f92-4976-b7ae-94b176fa73b1 22625006542000\n10 89e8296e-e076-4519-b916-60c5ef922292 22625006542500\n# ℹ more rows\n\n\nThis data only exists remotely still. We need to use collect to bring it down to our local machine. At the same time we can use dplyr pipelines to filter the data.\n\ncoast_sample |&gt;\n  dplyr::mutate(id = row_number()) |&gt;\n  dplyr::slice_min(n = 8, order_by = id) |&gt;\n  dplyr::collect()\n\n# A tibble: 8 × 3\n  havstrand_id                         ssbid               id\n  &lt;chr&gt;                                &lt;chr&gt;          &lt;int64&gt;\n1 4de8478a-d2c8-4730-83dd-12ac25d4fa07 22495006594500       1\n2 bc9a80d7-c434-47e9-a89a-7f7a3f59f625 22495006595000       2\n3 ce7166b6-cb49-499a-a99f-9da0e274abd8 22495006595500       3\n4 e56036c5-7fe4-461a-a022-44367119acac 22495006596000       4\n5 1f592dac-2fb7-49e5-9aa9-fc0cf9e9184f 22490006596500       5\n6 20394fe8-305c-4c39-add9-f013295ca932 22495006596500       6\n7 3d3ffe94-0400-4c1c-9a0f-62f4d6c29c4d 22490006597000       7\n8 4d199401-dd20-48ef-b6c6-8de00b9eb9a4 22495006597000       8\n\n\nWe can also get the geometries, which are stored in the foreign table. To do this we can use the dm package.\nWe first create a dm object from the connection object. Then we can view data easily.\n\ndm &lt;- dm::dm_from_con(con,\n  table_names = c(\n    \"ssb_500\",\n    \"samplingframe_havstrand_2024\",\n    \"samplingframe_vaatmark_2025\"\n  ),\n  learn_keys = T\n)\ndm\n\n── Table source ────────────────────────────────────────────────────────────────\nsrc:  postgres  [anders.kolstad@t2lippgsql03:5432/ano_moduler]\n── Metadata ────────────────────────────────────────────────────────────────────\nTables: `samplingframe_havstrand_2024`, `samplingframe_vaatmark_2025`, `ssb_500`\nColumns: 21\nPrimary keys: 3\nForeign keys: 2\n\n\nDM learns the relationships between tables by reading the constraints. First I can check that the amount of constraints is good.\n\ndm_get_all_fks(dm)\n\n\ndm |&gt;\n  dm::dm_set_colors(\n    darkgreen = samplingframe_havstrand_2024, \n    darkblue = ssb_500) |&gt;\n  dm::dm_draw() \n\n\nThen we can read the data back, including the geometries from the parent table.\n\ndm |&gt;\n  dm::dm_flatten_to_tbl(samplingframe_havstrand_2024,\n                    .recursive = TRUE)\n\n# Source:   SQL [?? x 3]\n# Database: postgres  [anders.kolstad@t2lippgsql03:5432/ano_moduler]\n   havstrand_id                         ssbid          geom                     \n   &lt;chr&gt;                                &lt;chr&gt;          &lt;pq_gmtry&gt;               \n 1 4de8478a-d2c8-4730-83dd-12ac25d4fa07 22495006594500 0103000020E9640000010000…\n 2 bc9a80d7-c434-47e9-a89a-7f7a3f59f625 22495006595000 0103000020E9640000010000…\n 3 ce7166b6-cb49-499a-a99f-9da0e274abd8 22495006595500 0103000020E9640000010000…\n 4 e56036c5-7fe4-461a-a022-44367119acac 22495006596000 0103000020E9640000010000…\n 5 1f592dac-2fb7-49e5-9aa9-fc0cf9e9184f 22490006596500 0103000020E9640000010000…\n 6 20394fe8-305c-4c39-add9-f013295ca932 22495006596500 0103000020E9640000010000…\n 7 3d3ffe94-0400-4c1c-9a0f-62f4d6c29c4d 22490006597000 0103000020E9640000010000…\n 8 4d199401-dd20-48ef-b6c6-8de00b9eb9a4 22495006597000 0103000020E9640000010000…\n 9 a34df6f4-8f92-4976-b7ae-94b176fa73b1 22625006542000 0103000020E9640000010000…\n10 89e8296e-e076-4519-b916-60c5ef922292 22625006542500 0103000020E9640000010000…\n# ℹ more rows\n\n\nThe geometry column is a bit weird though. Not sure what is happening there, but see this.",
    "crumbs": [
      "Read data from database",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Read data from the database</span>"
    ]
  },
  {
    "objectID": "030_simulation.html",
    "href": "030_simulation.html",
    "title": "\n6  Simulation\n",
    "section": "",
    "text": "6.1 Create dummy dataset\n# Create two variables with 60 values\ns1 &lt;- s2 &lt;- 1:60 - 0.5\n\n# set the per strata sample size\nn &lt;- 5\n\n# expand to get every combination\n# These will act as coordinates for our dummy data\nmypop &lt;- expand.grid(s1, s2)\n\n# name columns\nnames(mypop) &lt;- c(\"Easting\", \"Northing\")\n\n# add column 'stratum'\n# Strata '0' for when s1 is between -Inf and 4;\n# Strata '1' for when s1 is between 4 and 6; etc.\n# mypop$stratum &lt;- as.factor(findInterval(mypop$Easting, c(4, 6, 14)))\nmypop$stratum &lt;- as.factor(findInterval(mypop$Easting, c(12, 18, 42)))\n\n# give the strata names as capital letters\nlevels(mypop$stratum) &lt;- LETTERS[1:4]\n\n# add a column for area that can be used for pps\nmypop &lt;- mypop |&gt;\n  mutate(\n    area = case_when(\n      Northing &gt; 30 ~ 1,\n      .default = 0.3\n    ),\n    area2 = case_when(\n      Northing &gt; 10 ~ 1,\n      .default = 0.5\n    )\n  )\n\nmypop &lt;- mypop |&gt;\n  # get population size N,\n  # and the population area A_h,\n  # for each strata\n  group_by(stratum) |&gt;\n  summarise(\n    N_h = n(),\n    A_h = sum(area),\n    A_h2 = sum(area2), \n    .groups = \"drop\"\n  ) |&gt;\n  # calculate inclusion probability (pi) per strata, assuming we will sample 5 units\n  mutate(pi_h = rep(n, 4) / N_h) |&gt;\n  # join with the original data frame\n  right_join(mypop, by = \"stratum\") |&gt;\n  # adding also a pi based on the total area for each strata\n  mutate(pi_area = n * area / A_h,\n    # add unique ID's to each population unit\n    ID = row_number(),\n    # add mean values for response variables\n    res1_mean = case_when(\n      stratum == \"A\" ~ 5,\n      stratum == \"B\" ~ 10,\n      stratum == \"C\" ~ 15,\n      stratum == \"D\" ~ 20\n    ),\n    res2_mean = case_when(\n      stratum == \"A\" ~ 50,\n      stratum == \"B\" ~ 10,\n      stratum == \"C\" ~ 30,\n      stratum == \"D\" ~ 14,\n    )\n  ) |&gt;\n  # create dummy response variables\n  group_by(stratum) |&gt;\n  mutate(\n    res1 = rnorm(n = n(), mean = res1_mean, sd = 1),\n    res2 = rnorm(n = n(), mean = res2_mean, sd = 3),\n    # add dummy auxiliary variables\n    aux1 = seq(0.5, 5.5, length.out = n())^2,\n    aux2 = rgamma(n = n(), shape = .4)\n  ) |&gt;\n  ungroup() |&gt;\n  # round values (but don't round the probabilities)\n  mutate(across(starts_with(c(\"aux\", \"res\")), \\(x) round(x, 3))) |&gt;\n  dplyr::select(-res1_mean, -res2_mean)\nDT::datatable(mypop)\n\n\nTable 6.1: Dummy data\nThe probabilities all sum to the target n:\nmypop |&gt;\n  group_by(stratum) |&gt;\n  summarise(sum_pi_h = sum(pi_h),\n            sum_pi_area = sum(pi_area),\n            sum_area = sum(area))\nmypop |&gt;\n  pivot_longer(cols = starts_with(c(\"res\", \"aux\"))) |&gt;\n  ggplot() +\n  geom_histogram(aes(value),\n    bins = 50\n  ) +\n  facet_grid(\n    rows = vars(stratum), cols = vars(name),\n    scales = \"free\"\n  ) +\n  theme_bw()\n\n\n\n\n\n\nFigure 6.1: Histogram of response and auxilary variables in the dummy dataset.\ntableOfMeans &lt;- mypop |&gt;\n  pivot_longer(\n    cols = starts_with(c(\"res\", \"aux\", \"North\", \"East\")),\n    names_to = \"variable\", values_to = \"values\"\n  ) |&gt;\n  group_by(variable) |&gt;\n  summarise(\"Population mean\" = round(mean(values), 2),\n            \"Population variance\" = round(var(values), 2)) |&gt;\n  pivot_longer(cols = ends_with(\"mean\")) |&gt;\n  select(Variable = variable, \n         Sample = name,\n         mean = value, \n         variance = \"Population variance\") |&gt;\n  mutate(Sample = \"Population\")\n\ntableOfMeans |&gt;\n  kable()\n\n\nTable 6.2: Population seans. The aux variables are not correlated to the strata, but the res (response) variables do differ between strata.\n\n\n\n\nVariable\nSample\nmean\nvariance\n\n\n\nEasting\nPopulation\n30.00\n300.00\n\n\nNorthing\nPopulation\n30.00\n300.00\n\n\naux1\nPopulation\n11.09\n78.68\n\n\naux2\nPopulation\n0.40\n0.42\n\n\nres1\nPopulation\n13.99\n29.82\n\n\nres2\nPopulation\n27.31\n198.53\nmypop |&gt;\n  pivot_longer(\n    cols = starts_with(c(\"res\", \"aux\")),\n    names_to = \"variable\", values_to = \"values\"\n  ) |&gt;\n  group_by(variable, stratum) |&gt;\n  summarise(mean = round(mean(values), 2)) |&gt;\n  kable()\n\n`summarise()` has grouped output by 'variable'. You can override using the\n`.groups` argument.\n\n\n\nTable 6.3: Means for each strata. The aux variables are not correlated to the strata, but the res (response) variables do differ between strata.\n\n\n\n\nvariable\nstratum\nmean\n\n\n\naux1\nA\n11.09\n\n\naux1\nB\n11.09\n\n\naux1\nC\n11.09\n\n\naux1\nD\n11.09\n\n\naux2\nA\n0.40\n\n\naux2\nB\n0.37\n\n\naux2\nC\n0.40\n\n\naux2\nD\n0.41\n\n\nres1\nA\n5.01\n\n\nres1\nB\n9.99\n\n\nres1\nC\n14.99\n\n\nres1\nD\n19.97\n\n\nres2\nA\n50.10\n\n\nres2\nB\n9.91\n\n\nres2\nC\n30.14\n\n\nres2\nD\n14.13\nlw &lt;- .1\nggpubr::ggarrange(\n  ggplot(data = mypop) +\n    geom_tile(mapping = aes(x = Easting, y = Northing, fill = factor(stratum)), \n              width = 1, height = 1, linewidth = lw, colour = \"white\") +\n    scale_fill_viridis_d(name = \"Stratum\") +\n    coord_fixed(),\n  \n  ggplot(data = mypop) +\n    geom_tile(mapping = aes(x = Easting, y = Northing, fill = aux1), \n              width = 1, height = 1, linewidth = lw, colour = \"white\") +\n    scale_fill_viridis_c(name = \"aux1\") +\n    coord_fixed(),\n  \n  ggplot(data = mypop) +\n    geom_tile(mapping = aes(x = Easting, y = Northing, fill = aux2), \n              width = 1, height = 1, linewidth = lw, colour = \"white\") +\n    scale_fill_viridis_c(name = \"aux2\") +\n    coord_fixed(),\n  \n  ggplot(data = mypop) +\n    geom_tile(mapping = aes(x = Easting, y = Northing, fill = res1), \n              width = 1, height = 1, linewidth = lw, colour = \"white\") +\n    scale_fill_viridis_c(name = \"res1\") +\n    coord_fixed(),\n  \n  \n  ggplot(data = mypop) +\n    geom_tile(mapping = aes(x = Easting, y = Northing, fill = res2), \n              width = 1, height = 1, linewidth = lw, colour = \"white\") +\n    scale_fill_viridis_c(name = \"res2\") +\n    coord_fixed(),\n  \n  ggplot(data = mypop) +\n    geom_tile(mapping = aes(x = Easting, y = Northing, fill = factor(area)), \n              width = 1, height = 1, linewidth = lw, colour = \"white\") +\n    scale_fill_viridis_d(name = \"area\") +\n    coord_fixed()\n)\n\n\n\n\n\n\nFigure 6.2: Spatial distribution of the strata, and the four variables in the dummy dataset.",
    "crumbs": [
      "Spatial sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "030_simulation.html#stratified-simple-random-sample-ssrs",
    "href": "030_simulation.html#stratified-simple-random-sample-ssrs",
    "title": "\n6  Simulation\n",
    "section": "\n6.2 Stratified simple random sample (SSRS)",
    "text": "6.2 Stratified simple random sample (SSRS)\nThen I use the cube method in to select a sample balanced on the strata, essentially creating a stratified simple random sample. Here I use the sampling package. This is just a simple first test.\n\n# Create model matrix by expanding the strata column, explicitly assigning both presences and absences to each row.\nX &lt;- model.matrix(~ stratum -1, mypop)\nDT::datatable(X)\n\n\nTable 6.4: Model matrix\n\n\n\n\n\n\n\n\n\n\nset.seed(314)\nsample_ind &lt;- sampling::samplecube(X = X, pik = mypop$pi_h, comment = TRUE, method = 1)\n\n\nBEGINNING OF THE FLIGHT PHASE\nThe matrix of balanced variable has 4  variables and  3600  units\nThe size of the inclusion probability vector is  3600 \nThe sum of the inclusion probability vector is  20 \nThe inclusion probability vector has  3600  non-integer elements\nStep 1  Step  2 ,  \n\nNO LANDING PHASE\n\nQUALITY OF BALANCING\n         TOTALS HorvitzThompson_estimators Relative_deviation\nstratumA    720                        720      -2.526374e-13\nstratumB    360                        360      -1.578984e-13\nstratumC   1440                       1440      -2.842171e-13\nstratumD   1080                       1080       3.157968e-13\n\neps &lt;- 1e-6\nmysample &lt;- mypop[sample_ind &gt; (1 - eps), ]\n\nggplot(data = mypop) +\n  geom_tile(mapping = aes(x = Easting, y = Northing, fill = factor(stratum)), width = 1, height = 1, size = 0.5, colour = \"white\") +\n  geom_tile(data = mysample, mapping = aes(x = Easting, y = Northing), fill = NA, width = 1, height = 1, linewidth = 0.7, colour = \"black\") +\n  scale_fill_viridis_d(name = \"Stratum\") +\n  coord_fixed()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\nFigure 6.3: Sample balanced on a categorical variable (strata). This is equivalent to a stratified simple random sample.\n\n\n\n\nIn Figure 6.3, n= 5 for each strata. This is defined by the the sum of the inclusion probability vector, which is 20 in total.\n\n\n\nmypop |&gt;\n  ggplot() +\n  geom_histogram(aes(x = aux2, y = after_stat(density)),\n    binwidth = 1,\n    fill = \"blue\",\n    colour = \"black\",\n    alpha = .5\n  ) +\n  geom_histogram(\n    data = mysample,\n    aes(x = aux2, y = after_stat(density)),\n    binwidth = 1,\n    fill = \"red\",\n    colour = \"black\",\n    alpha = .5\n  ) +\n  facet_grid(. ~ stratum,\n    scales = \"free_x\"\n  )\n\n\n\n\n\n\nFigure 6.4: Histograms comparing the population distribution (blue, gamma distribution) with the sample from a stratified simple random sample when n = 5.",
    "crumbs": [
      "Spatial sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "030_simulation.html#balanced-sample",
    "href": "030_simulation.html#balanced-sample",
    "title": "\n6  Simulation\n",
    "section": "\n6.3 Balanced sample",
    "text": "6.3 Balanced sample\nNow I want to balance the sample on two auxiliary variables, as well as on the strata.\n\n# Create model matrix \nX2 &lt;- model.matrix(~ stratum + aux1 + aux2 - 1, mypop)\nDT::datatable(X2)\n\n\nTable 6.5: Model matrix #2\n\n\n\n\n\n\n\n\n\n\nset.seed(3141)\nsample_ind2 &lt;- sampling::samplecube(X = X2, pik = mypop$pi_h, comment = TRUE, method = 1)\n\n\nBEGINNING OF THE FLIGHT PHASE\nThe matrix of balanced variable has 6  variables and  3600  units\nThe size of the inclusion probability vector is  3600 \nThe sum of the inclusion probability vector is  20 \nThe inclusion probability vector has  3600  non-integer elements\nStep 1  \n\n\nBEGINNING OF THE LANDING PHASE\nAt the end of the flight phase, there remain  4 non integer probabilities \nThe sum of these probabilities is  2 \nThis sum is  integer\nThe linear program will consider  6  possible samples\nThe mean cost is  0.01412722 \nThe smallest cost is  0.000819588 \nThe largest cost is  0.0310499 \nThe cost of the selected sample is 0.000819588\n\nQUALITY OF BALANCING\n           TOTALS HorvitzThompson_estimators Relative_deviation\nstratumA   720.00                    720.000      -2.368476e-13\nstratumB   360.00                    360.000       0.000000e+00\nstratumC  1440.00                   1440.000       0.000000e+00\nstratumD  1080.00                   1080.000       8.421247e-14\naux1     39916.68                  39742.200      -4.371155e-01\naux2      1437.93                   1183.104      -1.772172e+01\n\nmysample2 &lt;- mypop[sample_ind2 &gt; (1 - eps), ]\n\nggplot(data = mypop) +\n  geom_tile(mapping = aes(x = Easting, y = Northing, fill = factor(stratum)), width = 1, height = 1, size = 0.5, colour = \"white\") +\n  geom_tile(data = mysample2, mapping = aes(x = Easting, y = Northing), fill = NA, width = 1, height = 1, linewidth = 0.7, colour = \"black\") +\n  scale_fill_viridis_d(name = \"Stratum\") +\n  coord_fixed()\n\n\n\n\n\n\nFigure 6.5: Sample balanced on two auxilary variables, as well as the categorical strata.\n\n\n\n\n\nmypop |&gt;\n  ggplot()+\n  geom_histogram(aes(x = aux2, y = after_stat(density)),\n                 binwidth = 1,\n                 fill = \"blue\",\n                 colour = \"black\",\n                 alpha = .5)+\n  geom_histogram(data = mysample2,\n                 aes(x = aux2, y = after_stat(density)),\n                 binwidth = 1,\n                 fill = \"red\",\n                 colour = \"black\",\n                 alpha = .5)+\n  facet_grid(.~stratum,\n             scales = \"free_x\")\n\n\n\n\n\n\nFigure 6.6: Histograms comparing the population distribution (blue, gamma distribution) with the sample from a stratified simple random sample when n = 10.\n\n\n\n\nIt appears from comparing Figure 6.4 with Figure 6.6 that the latter has a better overlap with the population distribution, although with n = 5 this is subject to a lot of chance still.",
    "crumbs": [
      "Spatial sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "030_simulation.html#balanced-and-well-spread",
    "href": "030_simulation.html#balanced-and-well-spread",
    "title": "\n6  Simulation\n",
    "section": "\n6.4 Balanced and well-spread",
    "text": "6.4 Balanced and well-spread\nThe samples do look like they are well-spread already, and not clumped. This might get different if n was bigger. Figure 6.7 shows how two and three neighboring cells frequently get selected.\n\nmypop &lt;- mypop |&gt;\n  mutate(pi_h2 = rep(40, 4) / N_h)\n\nset.seed(3143)\nsample_ind5 &lt;- sampling::samplecube(X = X2, pik = mypop$pi_h2, comment = TRUE, method = 1)\n\n\nBEGINNING OF THE FLIGHT PHASE\nThe matrix of balanced variable has 6  variables and  3600  units\nThe size of the inclusion probability vector is  3600 \nThe sum of the inclusion probability vector is  160 \nThe inclusion probability vector has  3600  non-integer elements\nStep 1  Step  2 ,  \n\n\nBEGINNING OF THE LANDING PHASE\nAt the end of the flight phase, there remain  3 non integer probabilities \nThe sum of these probabilities is  1 \nThis sum is  integer\nThe linear program will consider  3  possible samples\nThe mean cost is  0.007104658 \nThe smallest cost is  0.003841445 \nThe largest cost is  0.01309013 \nThe cost of the selected sample is 0.01309013\n\nQUALITY OF BALANCING\n           TOTALS HorvitzThompson_estimators Relative_deviation\nstratumA   720.00                    720.000       0.000000e+00\nstratumB   360.00                    360.000       1.578984e-14\nstratumC  1440.00                   1440.000       0.000000e+00\nstratumD  1080.00                   1080.000       0.000000e+00\naux1     39916.68                  40023.423       2.674095e-01\naux2      1437.93                   1565.154       8.847719e+00\n\nmysample5 &lt;- mypop[sample_ind5 &gt; (1 - eps), ]\n\nggplot(data = mypop) +\n  geom_tile(mapping = aes(x = Easting, y = Northing, fill = factor(stratum)), width = 1, height = 1, size = 0.5, colour = \"white\") +\n  geom_tile(data = mysample5, mapping = aes(x = Easting, y = Northing), fill = NA, width = 1, height = 1, linewidth = 0.7, colour = \"black\") +\n  scale_fill_viridis_d(name = \"Stratum\") +\n  coord_fixed()\n\n\n\n\n\n\nFigure 6.7: Balanced sample with n = 40\n\n\n\n\nWe can spread the samples geographically by balancing on the coordinates, but there are better ways, such as the local pivotal method. This is referred to as doubly balanced sampling. In Figure 6.8, sampling units are more spread, but can still occur next to each other.\n\n# model matrix, without the strata, which we now can add as a vector on the side\nX4 &lt;- model.matrix(~ aux1 + aux2 - 1, mypop)\n\n# define spreading variables (can be UTM coordinates)\nXspread &lt;- cbind(mypop$Easting, mypop$Northing)\nset.seed(314)\n\n\nsample_ind6 &lt;- BalancedSampling::lcubestratified(\n  prob = mypop$pi_h2,\n  Xspread = Xspread,\n  Xbal = X4,\n  integerStrat = mypop$stratum)\nmysample6 &lt;- mypop[sample_ind6,]\n\nggplot(data = mypop) +\n  geom_tile(mapping = aes(x = Easting, y = Northing, fill = factor(stratum)), width = 1, height = 1, size = 0.5, colour = \"white\") +\n  geom_tile(data = mysample6, mapping = aes(x = Easting, y = Northing), fill = NA, width = 1, height = 1, linewidth = 0.7, colour = \"black\") +\n  scale_fill_viridis_d(name = \"Stratum\") +\n  coord_fixed()\n\n\n\n\n\n\nFigure 6.8: Balanced and well-spread sample (n per strata is 40).",
    "crumbs": [
      "Spatial sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "030_simulation.html#pps",
    "href": "030_simulation.html#pps",
    "title": "\n6  Simulation\n",
    "section": "\n6.5 PPS",
    "text": "6.5 PPS\nNext i want to introduce sampling with ppr. The purpose is that we don’t want to spend too much time going to remote places only to find that the sampling unit is mostly just water. We want to reduce the change of selecting those units, but still keep the probability above 0 so that we can use the HT-estimator and get area-representative estimates of the population.\nPPR can be rather complex, and I’m not sure the solution here is the best or most correct. Basically, rather than calculating the inclusion probability as \\(n/N\\), I use \\(area/sum(area)\\).\n\nset.seed(3143)\nsample_ind4 &lt;- BalancedSampling::lcubestratified(\n  prob = mypop$pi_area,\n  Xspread = Xspread,\n  Xbal = X4,\n  integerStrat = mypop$stratum)\nmysample4 &lt;- mypop[sample_ind4, ]\n\nIn our example, using pps disfavored population units below a Northing of 30 (Figure 6.9), but kept the n as before.\n\nggplot(data = mypop) +\n  geom_tile(mapping = aes(x = Easting, y = Northing, fill = factor(stratum)), width = 1, height = 1, size = 0.5, colour = \"white\") +\n  geom_tile(data = mysample4, mapping = aes(x = Easting, y = Northing), fill = NA, width = 1, height = 1, linewidth = 0.7, colour = \"black\") +\n  scale_fill_viridis_d(name = \"Stratum\") +\n  coord_fixed()\n\n\n\n\n\n\nFigure 6.9: Balanced sample with inclusion probability proportional to size (area).",
    "crumbs": [
      "Spatial sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "030_simulation.html#comparison",
    "href": "030_simulation.html#comparison",
    "title": "\n6  Simulation\n",
    "section": "\n6.6 Comparison",
    "text": "6.6 Comparison\nThe relative differences between the Horvitz-Thompson estimators for the population means is very similar across all our samples. Aux2 is providing the best tet of balance perhaps, because it is an exponential variable. The balanced and well-spread sample had the smallest relative deviation for thet variable. But it could also be that n=5 is too little for getting stable and robust measures of deviation. A better validation would be to bootstrap the process and look at the variation in means then.\n\nht_results &lt;- lapply(vars, function(v) {\n  y &lt;- mysample6[[v]]\n  res &lt;- mase::horvitzThompson(y = y, pi = mysample6$pi_area, var_est = TRUE)\n  data.frame(\n    Balanced_spread = round(res$pop_mean, 2),\n    Balanced_spread_var = round(res$pop_mean_var,2)\n  )\n}) %&gt;%\n  bind_rows()\n\ntableOfMeans &lt;- tableOfMeans |&gt;\n  cbind(ht_results) |&gt;\n  mutate(Balanced_spread = mean/Balanced_spread)\n\ntableOfMeans |&gt;\n  select(!ends_with(\"var\"),\n         -mean, -variance, -Sample) |&gt;\n  pivot_longer(cols = !Variable) |&gt;\n  pivot_wider(names_from = Variable, values_from = value) |&gt;\n  kable()\n\n\nTable 6.6: Relative differences between HT-estimators for the population mean\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nEasting\nNorthing\naux1\naux2\nres1\nres2\n\n\n\nSRSS\n0.9759271\n1.171875\n1.202820\n0.6666667\n0.9879944\n0.9636556\n\n\nBalanced\n0.9652510\n0.990753\n1.004529\n1.2121212\n1.0093795\n0.9959883\n\n\nPPS\n0.8944544\n1.240695\n1.237723\n2.3529412\n0.9529973\n1.0680485\n\n\nBalanced_spread\n1.0288066\n1.388889\n1.591105\n0.9756098\n1.0014316\n1.0073774",
    "crumbs": [
      "Spatial sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "030_simulation.html#hierarchical-sampling",
    "href": "030_simulation.html#hierarchical-sampling",
    "title": "\n6  Simulation\n",
    "section": "\n6.7 Hierarchical sampling",
    "text": "6.7 Hierarchical sampling\nI want to create hierarchical samples that get reduced sequentially by x number of units each time. I will use x = 20 here to keep things simple. I can create a new sample based on the previous sample, but one worry is that any differences between the initial sample and the population can get reproduced, causing a kind of drift in the auxilary variables.\nOne option is then to sample, not from the consecutive sample, but from the entire population, and instead set the probabilities (pi) for those that were not already selected, to zero. That way the sub-samples are still balanced relative to the entire population.\nThe pi of a unit will then have to be calculated post hoc based on the n of the sample it came from (Section 6.8).\nLet’s create the first large sample, using n = 100. Because we really exaggerated the area variable, we could get the remaining area (the summed area in the sampled) to be less than the next sample size. Therefore I will use area2 which make the differences in area a little less dramatic.\n\n# The n is per strata. \nn &lt;- 100\n\ntemp &lt;- mypop |&gt;\n      mutate(pi = n * area2 / A_h2)\n\n# Sums are OK:\n#temp |&gt;\n#  group_by(stratum) |&gt;\n#  summarise(pi_summed = sum(pi))\n\nset.seed(3143)\nsample_100_indices &lt;- BalancedSampling::lcubestratified(\n  prob = temp$pi,\n  Xspread = Xspread,\n  Xbal = X4,\n  integerStrat = mypop$stratum)\nsample_100 &lt;- mypop[sample_100_indices, ]\n\nggplot(data = mypop) +\n  geom_tile(\n    mapping = aes(x = Easting, y = Northing, fill = factor(stratum)),\n    width = 1, height = 1, size = 0.5, colour = \"white\"\n  ) +\n  geom_tile(\n    data = sample_100, mapping = aes(x = Easting, y = Northing),\n    fill = NA, width = 1, height = 1, linewidth = 0.7, colour = \"black\"\n  ) +\n  scale_fill_viridis_d(name = \"Stratum\") +\n  coord_fixed()\n\n\n\nBalanced sample (total n = 100) with inclusion probability proportional to size (area).\n\n\n\nThen we create nested samples.\n\ncurrentSample &lt;- sample_100\n\nall_selected &lt;- currentSample$ID\n\nfor (n in seq(80, 20, -20)) {\n  # print(n)\n  previousSample &lt;- currentSample$ID\n\n  Xspread &lt;- tibble(\n    E = mypop$Easting,\n    N = mypop$Northing\n  ) |&gt;\n    mutate(\n      ID = row_number(),\n      E = case_when(\n        ID %in% previousSample ~ E,\n        .default = 999\n      ), # tested with 30 to see if we got a bias, but no\n      N = case_when(\n        ID %in% previousSample ~ N,\n        .default = 999\n      )\n    ) |&gt;\n    select(-ID) |&gt;\n    as.matrix()\n\n  temp &lt;- mypop |&gt;\n    mutate(area2 = case_when(\n      ID %in% previousSample ~ area2,\n      .default = 0\n    ))\n\n  temp &lt;- temp |&gt;\n    group_by(stratum) |&gt;\n    summarise(remainingArea = sum(area2), .groups = \"drop\") |&gt;\n    right_join(temp, by = \"stratum\") |&gt;\n    mutate(pi = n * area2 / remainingArea)\n\n  sample_indices &lt;- BalancedSampling::lcubestratified(\n    prob = temp$pi,\n    Xspread = Xspread,\n    Xbal = X4,\n    integerStrat = mypop$stratum\n  )\n\n  currentSample &lt;- mypop[sample_indices, ]\n\n  assign(paste0(\"sample_\", n), currentSample)\n  all_selected &lt;- c(all_selected, currentSample$ID)\n}\n\n\n all_selected |&gt;\n  as_tibble() |&gt;\n  rename(ID = value) |&gt;\n  group_by(ID) |&gt;\n  summarise(no_selected = n()) |&gt;\n  right_join(mypop, by = \"ID\") |&gt;\n  ggplot() +\n  geom_tile(mapping = aes(x = Easting, y = Northing, fill = factor(no_selected)), \n            width = 1, height = 1, linewidth = 0.5, colour = \"white\") +\n  scale_fill_viridis_d(name = \"Number of times selected\", option = \"C\", direction = -1) +\n  coord_fixed()\n\n\n\n\n\n\nFigure 6.10: Figure showing the selected population units, and how many of the in total five nestes samples they were included in.\n\n\n\n\n\nggplot(data = mypop) +\n  geom_tile(\n    mapping = aes(x = Easting, y = Northing, fill = factor(stratum)),\n    width = 1, height = 1, size = 0.5, colour = \"white\"\n  ) +\n  geom_tile(\n    data = sample_20, mapping = aes(x = Easting, y = Northing),\n    fill = NA, width = 1, height = 1, linewidth = 0.7, colour = \"black\"\n  ) +\n  scale_fill_viridis_d(name = \"Stratum\") +\n  coord_fixed()\n\n\n\n\n\n\nFigure 6.11: The smalles of the hierarchical samples (n = 20).\n\n\n\n\nIt still a question whether the final or smallest sample (Figure 6.11) is balanced. A superfical analyses tells us it’s looking good (Figure 6.12).\n\nmypop |&gt;\n  ggplot() +\n  geom_histogram(aes(x = aux2, y = after_stat(density)),\n    binwidth = 1,\n    fill = \"blue\",\n    colour = \"black\",\n    alpha = .5\n  ) +\n  geom_histogram(\n    data = sample_20,\n    aes(x = aux2, y = after_stat(density)),\n    binwidth = 1,\n    fill = \"red\",\n    colour = \"black\",\n    alpha = .5\n  ) +\n  facet_grid(. ~ stratum,\n    scales = \"free_x\"\n  )\n\n\n\n\n\n\nFigure 6.12: Histograms comparing the smallest of the nested samples (red) against the true population (blue).",
    "crumbs": [
      "Spatial sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "030_simulation.html#sec-what",
    "href": "030_simulation.html#sec-what",
    "title": "\n6  Simulation\n",
    "section": "\n6.8 Whats the pi?",
    "text": "6.8 Whats the pi?\nNow say we end up using sample20 for stratum A and sample40 for stratum B. What pi’s should we use when calculating the HT-estimator?\nWe should use the original A_h (from the entire population), and the n from the specific sample (i.e. 20 and 40 in this case, respectively.)",
    "crumbs": [
      "Spatial sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "030_simulation.html#create-function",
    "href": "030_simulation.html#create-function",
    "title": "\n6  Simulation\n",
    "section": "\n6.9 Create function",
    "text": "6.9 Create function\nBased on the above, and with the help of ChatGPT [version 5), I created a contained function nested_balanced_samples that we can source in subsequent chapters. You can fund in under R/ in the github repo.\n\nsource(here::here(\"R/nested_balanced_samples.R\"))",
    "crumbs": [
      "Spatial sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simulation</span>"
    ]
  }
]